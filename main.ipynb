{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "## Process missing data\n",
    "### Set parameter 'type_of_processed_missing' to a valid value ('mean','median','zero_padding')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_missing_data import ProcessingMissingData\n",
    "import pickle\n",
    "## Processing the dataset with the class ProcessingMissingData\n",
    "\n",
    "## Load train data\n",
    "## Process the data with the sampler and segmenter\n",
    "with open('Data\\\\train_inputs.pkl', 'rb') as handle:\n",
    "    list_of_trains = pickle.load(handle)\n",
    "\n",
    "processing_missing_data_obj = ProcessingMissingData()\n",
    "## type accepts - 'mean', 'median', 'zero_padding'\n",
    "type_of_processed_missing = 'zero_padding'\n",
    "list_of_missing_vals_processed_trains_concat = processing_missing_data_obj.get_processed_dataset_as_list_of_vectors(list_of_data=list_of_trains, type=type_of_processed_missing)\n",
    "\n",
    "list_of_missing_preprocessed_trains = processing_missing_data_obj.get_processed_dataset(list_of_data=list_of_trains, type=type_of_processed_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.860936e+00,  1.891651e+00,  1.939205e+00,  1.717517e+00,\n",
       "        1.741191e+00,  1.684695e+00,  1.637373e+00,  1.643283e+00,\n",
       "        1.607030e+00,  1.617907e+00,  1.510350e+00,  1.371225e+00,\n",
       "        1.299045e+00,  1.221498e+00,  1.181849e+00,  1.161630e+00,\n",
       "        1.194990e+00,  1.264847e+00,  1.250698e+00,  1.261441e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00, -2.073830e-01, -1.932490e-01,\n",
       "       -2.396640e-01, -2.185720e-01, -2.798910e-01, -3.119770e-01,\n",
       "       -3.362270e-01, -3.497730e-01, -3.827450e-01, -5.273670e-01,\n",
       "       -5.480250e-01, -4.709880e-01, -4.950950e-01, -5.000800e-01,\n",
       "       -4.964390e-01, -4.819330e-01, -5.109640e-01, -5.648780e-01,\n",
       "       -6.122910e-01, -6.383500e-01,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        2.615570e-01,  2.353630e-01,  2.585610e-01,  2.171190e-01,\n",
       "        1.965830e-01,  1.954530e-01,  1.527660e-01,  1.315530e-01,\n",
       "        1.790380e-01,  1.798780e-01,  1.319300e-01,  4.316300e-02,\n",
       "        2.937500e-02, -2.802000e-03, -7.519300e-02, -5.229100e-02,\n",
       "        6.582700e-02,  1.629070e-01,  2.057010e-01,  2.174430e-01,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00, -2.145620e-01, -2.491180e-01,\n",
       "       -2.914580e-01, -2.281860e-01, -2.363770e-01, -2.319700e-01,\n",
       "       -2.238420e-01, -1.545190e-01, -1.159490e-01, -8.329200e-02,\n",
       "       -2.803600e-02,  1.916600e-02,  2.641800e-02,  9.556500e-02,\n",
       "        1.672880e-01,  1.566740e-01,  1.757910e-01,  1.867450e-01,\n",
       "        2.110030e-01,  2.633840e-01,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "       -1.712530e-01, -1.128900e-01, -4.105300e-02, -1.860800e-02,\n",
       "       -3.201200e-02, -6.867000e-02, -2.627800e-02, -3.529200e-02,\n",
       "       -6.040600e-02,  3.174700e-02,  1.047820e-01,  1.651040e-01,\n",
       "        2.182880e-01,  2.268360e-01,  2.942190e-01,  3.612260e-01,\n",
       "        3.536180e-01,  3.568600e-01,  3.697120e-01,  3.911150e-01,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00, -1.181670e-01, -1.122380e-01,\n",
       "       -1.020340e-01, -1.376240e-01, -9.061200e-02, -3.822000e-03,\n",
       "       -9.157000e-03,  2.371900e-02,  5.780000e-02,  8.142400e-02,\n",
       "        9.202700e-02,  9.589000e-02,  7.575000e-02,  5.546300e-02,\n",
       "        9.977000e-03, -2.937200e-02, -6.670200e-02, -1.035970e-01,\n",
       "       -1.353270e-01, -1.768970e-01,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "       -2.775570e-01, -3.119970e-01, -3.833000e-01, -4.033180e-01,\n",
       "       -3.631340e-01, -3.419400e-01, -3.638660e-01, -3.813990e-01,\n",
       "       -3.646420e-01, -4.182270e-01, -4.167920e-01, -4.166920e-01,\n",
       "       -3.748730e-01, -3.744770e-01, -4.003000e-01, -4.393980e-01,\n",
       "       -4.830340e-01, -4.775840e-01, -5.119180e-01, -5.106970e-01,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  2.566800e-02, -2.712200e-02,\n",
       "        1.901300e-02, -9.643000e-03, -1.257100e-02, -8.826000e-03,\n",
       "       -3.117000e-03, -2.118900e-02, -6.923000e-02, -8.117500e-02,\n",
       "       -1.206350e-01, -1.595740e-01, -1.915420e-01, -2.331650e-01,\n",
       "       -2.335760e-01, -1.537790e-01, -6.115000e-02, -3.612300e-02,\n",
       "       -8.747000e-03,  2.052600e-02,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        1.267010e-01,  1.714570e-01,  1.695100e-01,  1.646070e-01,\n",
       "        1.242980e-01,  8.509700e-02,  5.547900e-02,  2.039700e-02,\n",
       "       -1.978800e-02, -2.238500e-02, -5.644200e-02, -7.884700e-02,\n",
       "       -1.037740e-01, -6.483800e-02, -6.719700e-02, -1.447690e-01,\n",
       "       -1.965650e-01, -2.185470e-01, -2.036370e-01, -2.177090e-01,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00, -3.067560e-01, -2.894310e-01,\n",
       "       -3.148940e-01, -3.232670e-01, -3.511710e-01, -3.643290e-01,\n",
       "       -3.581070e-01, -3.404910e-01, -3.559960e-01, -3.376600e-01,\n",
       "       -3.088500e-01, -3.268130e-01, -3.222660e-01, -2.962190e-01,\n",
       "       -2.365040e-01, -2.143680e-01, -2.204770e-01, -2.049740e-01,\n",
       "       -2.129820e-01, -2.190710e-01,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "       -2.130760e-01, -2.477220e-01, -2.279080e-01, -2.101050e-01,\n",
       "       -2.165450e-01, -2.047940e-01, -1.816430e-01, -1.564170e-01,\n",
       "       -1.151290e-01, -1.031840e-01, -9.958700e-02, -7.388200e-02,\n",
       "       -6.612200e-02, -7.588500e-02, -9.684400e-02, -6.880400e-02,\n",
       "       -2.792000e-02, -1.911900e-02, -2.357000e-02, -3.331400e-02,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  8.872800e-02,  9.301100e-02,\n",
       "        7.463800e-02,  9.809800e-02,  1.138990e-01,  1.018380e-01,\n",
       "        8.205600e-02,  8.088400e-02,  1.319280e-01,  1.022660e-01,\n",
       "        1.035290e-01,  1.410550e-01,  1.307220e-01,  9.197300e-02,\n",
       "        1.037300e-02, -4.104700e-02, -8.543600e-02, -1.368570e-01,\n",
       "       -1.704980e-01, -1.759860e-01,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        1.000000e+00,  2.000000e+00,  3.000000e+00])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "## Concatenating two numpy arrays demo (needed for Kaan's method)\n",
    "np.concatenate((list_of_missing_vals_processed_trains_concat[0], np.array([1,2,3])))"
   ]
  },
  {
   "source": [
    "## Process data to be ready to segment/sample\n",
    "### Uncomment/Comment the correct 'curr_list_of_trains' depending if you want the raw data or with filled missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from person_processing import PersonProcessing\n",
    "import pickle\n",
    "\n",
    "## Process the data with the sampler and segmenter\n",
    "with open('Data\\\\train_inputs.pkl', 'rb') as handle:\n",
    "    list_of_trains = pickle.load(handle)\n",
    "\n",
    "\n",
    "# RAW TRAINS or WITHOUT MISSING DATA TRAINS\n",
    "curr_list_of_trains = list_of_trains # RAW\n",
    "#curr_list_of_trains = list_of_missing_preprocessed_trains # Filled missing values data\n",
    "\n",
    "# parameter k\n",
    "param_k = 5   \n",
    "# dict with key k number of samples taken and value list of vectors for that particular k\n",
    "# dict with key k number of segmentations taken and value list of vectors for that particular k\n",
    "dict_of_k_samples_features = dict()\n",
    "dict_of_k_segmentations_features = dict()\n",
    "for train_sample in curr_list_of_trains:\n",
    "    for curr_k in range(2,param_k+1):\n",
    "        person_processing_obj = PersonProcessing(train_sample)\n",
    "        results_sampling = person_processing_obj.get_sampling(k=curr_k)\n",
    "        results_segmentation = person_processing_obj.get_segmentation(k=curr_k)\n",
    "\n",
    "        if curr_k in dict_of_k_samples_features:\n",
    "            dict_of_k_samples_features[curr_k].append(results_sampling)\n",
    "        else:\n",
    "            dict_of_k_samples_features[curr_k] = list()\n",
    "            dict_of_k_samples_features[curr_k].append(results_sampling)\n",
    "\n",
    "        if curr_k in dict_of_k_segmentations_features:\n",
    "            dict_of_k_segmentations_features[curr_k].append(results_segmentation)\n",
    "        else:\n",
    "            dict_of_k_segmentations_features[curr_k] = list()\n",
    "            dict_of_k_segmentations_features[curr_k].append(results_segmentation)"
   ]
  },
  {
   "source": [
    "## Process the labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the labels\n",
    "with open('Data\\\\train_outputs.pkl', 'rb') as handle:\n",
    "    list_of_train_labels_raw = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_train_labels = list()\n",
    "for item in list_of_train_labels_raw:\n",
    "    label_idx = (item[0] == 1).nonzero()[0][0]\n",
    "    list_of_train_labels.append(label_idx)"
   ]
  },
  {
   "source": [
    "## Neural Network Architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network Architecture\n",
    "from torch import nn\n",
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class JapaneseVowelsNN(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes, dropout_rate):\n",
    "        super(JapaneseVowelsNN, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(feature_dim, feature_dim*2)\n",
    "        self.hidden_layer = nn.Linear(feature_dim*2, feature_dim)\n",
    "        self.hidden_layer2 = nn.Linear(feature_dim, int(feature_dim/2))\n",
    "        self.output_layer = nn.Linear(int(feature_dim/2), num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(feature_dim*2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(feature_dim)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(int(feature_dim/2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "source": [
    "## Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from passing_through_regions import FeatureSelection\n",
    "\n",
    "## Function for creating the data loaders and making train validate sets\n",
    "def prepare_dataset(type='segmentation', k=2):\n",
    "    if type=='segmentation':\n",
    "        dataset = list(zip(torch.from_numpy(np.array(dict_of_k_segmentations_features[k])), \n",
    "        torch.from_numpy(np.array(list_of_train_labels))))\n",
    "\n",
    "    elif type=='sampling':\n",
    "        dataset = list(zip(torch.from_numpy(np.array(dict_of_k_samples_features[k])), \n",
    "        torch.from_numpy(np.array(list_of_train_labels))))\n",
    "\n",
    "    elif type=='processed_missing':\n",
    "        dataset = list(zip(torch.from_numpy(np.array(list_of_missing_vals_processed_trains_concat)), \n",
    "        torch.from_numpy(np.array(list_of_train_labels))))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def prepare_pca_train_val_data(train_data, val_data, train_labels_pca, val_labels_pca, n_components=200):\n",
    "    features = FeatureSelection(train_data, n_pc=n_components)\n",
    "    transformed_train_data = features.get_training_features()\n",
    "    transformed_val_data = features.pca_transform_data(val_data)\n",
    "\n",
    "    # concat with labels\n",
    "    train_data = list(zip(torch.from_numpy(np.array(transformed_train_data)), \n",
    "        torch.from_numpy(np.array(train_labels_pca))))\n",
    "    val_data = list(zip(torch.from_numpy(np.array(transformed_val_data)), \n",
    "        torch.from_numpy(np.array(val_labels_pca))))\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def create_cross_validator(n_splits=10):\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    return cv\n",
    "\n",
    "def create_data_loaders(train_data, val_data):\n",
    "    train_data_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_data_loader = DataLoader(dataset=val_data, batch_size=1, shuffle=False)\n",
    "    return train_data_loader, val_data_loader"
   ]
  },
  {
   "source": [
    "## Parameter settings\n",
    "### Set 'TYPE_OF_FEATURES' depending if you want to make experiments for processed_missing, segmentation or sampling\n",
    "### If you want to make experiment with segmentation + processed_missing (for example segment mean but from data filled with zero padding), make sure that you have set 'curr_list_of_trains' in section 'Process data to be ready to segment\\sampling' in the beggining of the notebook to take the filled missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 27\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 9\n",
    "K_FOLD_SPLITS = 10\n",
    "\n",
    "optimizer_name = 'Adam'\n",
    "## For automating experiments with different dropout\n",
    "## Here we are testing from 0 to 0.5\n",
    "range_of_dropout = [p/10 for p in range(0, 6)]\n",
    "\n",
    "# Possible types: \"segmentation\", \"sampling\", \"processed_missing\", \"passing_regions_PCA\"\n",
    "## Super important to be set correctly as it is used for saving the experiment in the correct dir\n",
    "\n",
    "###########\n",
    "TYPE_OF_FEATURES = \"passing_regions_PCA\"\n",
    "###########\n",
    "\n",
    "\n",
    "if TYPE_OF_FEATURES == \"processed_missing\":\n",
    "    ## So we can get the directory 'processed_missing\\\\mean\\\\...'\n",
    "    ## OR 'processed_missing\\\\median\\\\...' OR 'processed_missing\\\\zero_padding\\\\...'\n",
    "    ## Basically the type of processed missing\n",
    "    sub_folder = type_of_processed_missing\n",
    "    ## Set to zero if type=\"processed_missing\"\n",
    "    K = 0\n",
    "    LOOP_START_AT = 0\n",
    "elif TYPE_OF_FEATURES == 'segmentation':\n",
    "    # if TYPE_OF_FEATURES == segmentation, we want to have the structure 'segmentation\\\\zero_padding\\\\...'\n",
    "    ## OR 'segmentation\\\\mean\\\\...' and so on. \n",
    "    ## Basically the type of segmentation\n",
    "\n",
    "    # In the case where we have segmentation without filling missing values\n",
    "    if curr_list_of_trains[0].shape[0] < 26:\n",
    "        sub_folder = 'no_filling_missing'\n",
    "    else:\n",
    "        sub_folder = type_of_processed_missing\n",
    "    K = param_k\n",
    "    LOOP_START_AT = 5\n",
    "elif TYPE_OF_FEATURES == 'passing_regions_PCA':\n",
    "    K = 0\n",
    "    LOOP_START_AT = 0\n",
    "    N_COMP = 60\n",
    "    sub_folder = 'n_comp_{}'.format(N_COMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_COMP = 60\n",
    "#train_data_pca = itemgetter(*train_idx)(list_of_trains)\n",
    "#val_data_pca = itemgetter(*val_idx)(list_of_trains)\n",
    "# Fit transform the training and just transform the validation\n",
    "#transformed_train_data_pca, transformed_val_data_pca = \\\n",
    "#prepare_pca_train_val_data(list_of_trains[:244], list_of_trains[244:], N_COMP)\n",
    "# Create data loaders for train-val for the current cross validation\n",
    "#train_loader, val_loader = \\\n",
    "#create_data_loaders(train_data=transformed_train_data_pca, val_data=transformed_val_data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ERROR MESSAGE\n",
    "## Input contains NaN, infinity or a value too large for dtype('float64'), WHEN\n",
    "## method 'get_training_features' is processed when we want to transform the VALIDATION data.\n",
    "## Transform is working on the training!!!\n",
    "## Tried fixes:\n",
    "## 1. Change random state to something else to see if it is based on the certain batch of data\n",
    "## 2. Change the components from 60 to 0.96 (both these work in the example in the 'passing_trhough_regions.py')   \n",
    "\n",
    "# might help: https://www.xspdf.com/resolution/50760548.html"
   ]
  },
  {
   "source": [
    "## Training. It consists of nested loops, their structure is as follows: <br>\n",
    "### 1. Loop for dropout rate\n",
    "###  &emsp;  2. Loop for k-segments (right now k=5 and the loop is static as we don't want other values for k right now)\n",
    "###    &emsp; &emsp;   3. Loop for 10-fold cross validation\n",
    "###     &emsp; &emsp; &emsp;     4. Loop for epochs\n",
    "## After Loop 3 has completed, the following happens:\n",
    "### 1. Result folder structure is created if it doesn't exist\n",
    "### 2. Results are saved for the current dropout rate as pickle so they can be analyzed later"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 1.493 |  Val Loss: 1.839 | Train acc: 88.889 | Val acc: 48.148\n",
      "Epoch: 70 | Train Loss: 1.369 |  Val Loss: 1.756 | Train acc: 100.0 | Val acc: 55.556\n",
      "Epoch: 80 | Train Loss: 1.3 |  Val Loss: 1.772 | Train acc: 88.889 | Val acc: 51.852\n",
      "Epoch: 90 | Train Loss: 1.164 |  Val Loss: 1.708 | Train acc: 100.0 | Val acc: 55.556\n",
      "Epoch: 100 | Train Loss: 1.077 |  Val Loss: 1.655 | Train acc: 100.0 | Val acc: 51.852\n",
      "Epoch: 110 | Train Loss: 0.966 |  Val Loss: 1.678 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 120 | Train Loss: 0.865 |  Val Loss: 1.656 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 130 | Train Loss: 0.789 |  Val Loss: 1.667 | Train acc: 100.0 | Val acc: 51.852\n",
      "Epoch: 140 | Train Loss: 0.781 |  Val Loss: 1.593 | Train acc: 100.0 | Val acc: 51.852\n",
      "Epoch: 150 | Train Loss: 0.68 |  Val Loss: 1.613 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 160 | Train Loss: 0.634 |  Val Loss: 1.665 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 170 | Train Loss: 0.632 |  Val Loss: 1.652 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 180 | Train Loss: 0.6 |  Val Loss: 1.774 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 190 | Train Loss: 0.529 |  Val Loss: 1.634 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 200 | Train Loss: 0.482 |  Val Loss: 1.682 | Train acc: 100.0 | Val acc: 37.037\n",
      "--------k param: 0 k-fold num: 6 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.103 |  Val Loss: 2.044 | Train acc: 11.111 | Val acc: 25.926\n",
      "Epoch: 20 | Train Loss: 1.99 |  Val Loss: 2.003 | Train acc: 22.222 | Val acc: 29.63\n",
      "Epoch: 30 | Train Loss: 1.89 |  Val Loss: 1.998 | Train acc: 55.556 | Val acc: 29.63\n",
      "Epoch: 40 | Train Loss: 1.829 |  Val Loss: 1.944 | Train acc: 77.778 | Val acc: 33.333\n",
      "Epoch: 50 | Train Loss: 1.745 |  Val Loss: 1.899 | Train acc: 88.889 | Val acc: 29.63\n",
      "Epoch: 60 | Train Loss: 1.656 |  Val Loss: 1.916 | Train acc: 100.0 | Val acc: 33.333\n",
      "Epoch: 70 | Train Loss: 1.604 |  Val Loss: 1.894 | Train acc: 100.0 | Val acc: 29.63\n",
      "Epoch: 80 | Train Loss: 1.52 |  Val Loss: 1.879 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 90 | Train Loss: 1.417 |  Val Loss: 1.876 | Train acc: 100.0 | Val acc: 33.333\n",
      "Epoch: 100 | Train Loss: 1.36 |  Val Loss: 1.82 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 110 | Train Loss: 1.295 |  Val Loss: 1.838 | Train acc: 100.0 | Val acc: 37.037\n",
      "Epoch: 120 | Train Loss: 1.214 |  Val Loss: 1.876 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 130 | Train Loss: 1.102 |  Val Loss: 1.846 | Train acc: 100.0 | Val acc: 37.037\n",
      "Epoch: 140 | Train Loss: 1.057 |  Val Loss: 1.824 | Train acc: 100.0 | Val acc: 37.037\n",
      "Epoch: 150 | Train Loss: 0.979 |  Val Loss: 1.844 | Train acc: 100.0 | Val acc: 33.333\n",
      "Epoch: 160 | Train Loss: 0.939 |  Val Loss: 1.862 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 170 | Train Loss: 0.861 |  Val Loss: 1.892 | Train acc: 100.0 | Val acc: 33.333\n",
      "Epoch: 180 | Train Loss: 0.823 |  Val Loss: 1.91 | Train acc: 100.0 | Val acc: 33.333\n",
      "Epoch: 190 | Train Loss: 0.758 |  Val Loss: 1.813 | Train acc: 100.0 | Val acc: 37.037\n",
      "Epoch: 200 | Train Loss: 0.733 |  Val Loss: 1.888 | Train acc: 100.0 | Val acc: 33.333\n",
      "--------k param: 0 k-fold num: 7 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.093 |  Val Loss: 2.195 | Train acc: 11.111 | Val acc: 22.222\n",
      "Epoch: 20 | Train Loss: 2.028 |  Val Loss: 2.163 | Train acc: 22.222 | Val acc: 18.519\n",
      "Epoch: 30 | Train Loss: 1.955 |  Val Loss: 2.137 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 40 | Train Loss: 1.863 |  Val Loss: 2.113 | Train acc: 77.778 | Val acc: 22.222\n",
      "Epoch: 50 | Train Loss: 1.803 |  Val Loss: 2.121 | Train acc: 55.556 | Val acc: 18.519\n",
      "Epoch: 60 | Train Loss: 1.714 |  Val Loss: 2.099 | Train acc: 88.889 | Val acc: 22.222\n",
      "Epoch: 70 | Train Loss: 1.662 |  Val Loss: 2.103 | Train acc: 77.778 | Val acc: 18.519\n",
      "Epoch: 80 | Train Loss: 1.601 |  Val Loss: 2.076 | Train acc: 100.0 | Val acc: 11.111\n",
      "Epoch: 90 | Train Loss: 1.542 |  Val Loss: 2.104 | Train acc: 77.778 | Val acc: 11.111\n",
      "Epoch: 100 | Train Loss: 1.433 |  Val Loss: 2.092 | Train acc: 100.0 | Val acc: 7.407\n",
      "Epoch: 110 | Train Loss: 1.386 |  Val Loss: 2.092 | Train acc: 100.0 | Val acc: 14.815\n",
      "Epoch: 120 | Train Loss: 1.35 |  Val Loss: 2.09 | Train acc: 100.0 | Val acc: 18.519\n",
      "Epoch: 130 | Train Loss: 1.26 |  Val Loss: 2.054 | Train acc: 100.0 | Val acc: 14.815\n",
      "Epoch: 140 | Train Loss: 1.176 |  Val Loss: 2.053 | Train acc: 100.0 | Val acc: 18.519\n",
      "Epoch: 150 | Train Loss: 1.117 |  Val Loss: 2.055 | Train acc: 100.0 | Val acc: 11.111\n",
      "Epoch: 160 | Train Loss: 1.069 |  Val Loss: 2.121 | Train acc: 100.0 | Val acc: 18.519\n",
      "Epoch: 170 | Train Loss: 1.007 |  Val Loss: 2.057 | Train acc: 100.0 | Val acc: 25.926\n",
      "Epoch: 180 | Train Loss: 1.002 |  Val Loss: 2.065 | Train acc: 100.0 | Val acc: 14.815\n",
      "Epoch: 190 | Train Loss: 0.91 |  Val Loss: 2.056 | Train acc: 100.0 | Val acc: 18.519\n",
      "Epoch: 200 | Train Loss: 0.879 |  Val Loss: 2.042 | Train acc: 100.0 | Val acc: 11.111\n",
      "--------k param: 0 k-fold num: 8 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.052 |  Val Loss: 2.159 | Train acc: 11.111 | Val acc: 14.815\n",
      "Epoch: 20 | Train Loss: 1.897 |  Val Loss: 2.019 | Train acc: 44.444 | Val acc: 29.63\n",
      "Epoch: 30 | Train Loss: 1.779 |  Val Loss: 1.927 | Train acc: 77.778 | Val acc: 29.63\n",
      "Epoch: 40 | Train Loss: 1.68 |  Val Loss: 1.923 | Train acc: 77.778 | Val acc: 18.519\n",
      "Epoch: 50 | Train Loss: 1.557 |  Val Loss: 1.867 | Train acc: 88.889 | Val acc: 33.333\n",
      "Epoch: 60 | Train Loss: 1.44 |  Val Loss: 1.87 | Train acc: 100.0 | Val acc: 29.63\n",
      "Epoch: 70 | Train Loss: 1.355 |  Val Loss: 1.894 | Train acc: 88.889 | Val acc: 29.63\n",
      "Epoch: 80 | Train Loss: 1.262 |  Val Loss: 1.864 | Train acc: 100.0 | Val acc: 37.037\n",
      "Epoch: 90 | Train Loss: 1.142 |  Val Loss: 1.874 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 100 | Train Loss: 1.032 |  Val Loss: 1.883 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 110 | Train Loss: 0.952 |  Val Loss: 1.824 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 120 | Train Loss: 0.835 |  Val Loss: 1.781 | Train acc: 100.0 | Val acc: 48.148\n",
      "Epoch: 130 | Train Loss: 0.829 |  Val Loss: 1.819 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 140 | Train Loss: 0.715 |  Val Loss: 1.785 | Train acc: 100.0 | Val acc: 44.444\n",
      "Epoch: 150 | Train Loss: 0.719 |  Val Loss: 1.85 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 160 | Train Loss: 0.61 |  Val Loss: 1.789 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 170 | Train Loss: 0.578 |  Val Loss: 1.775 | Train acc: 100.0 | Val acc: 40.741\n",
      "Epoch: 180 | Train Loss: 0.545 |  Val Loss: 1.908 | Train acc: 100.0 | Val acc: 29.63\n",
      "Epoch: 190 | Train Loss: 0.52 |  Val Loss: 1.95 | Train acc: 100.0 | Val acc: 25.926\n",
      "Epoch: 200 | Train Loss: 0.455 |  Val Loss: 1.961 | Train acc: 100.0 | Val acc: 40.741\n",
      "--------k param: 0 k-fold num: 9 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.221 |  Val Loss: 440.832 | Train acc: 0.0 | Val acc: 7.407\n",
      "Epoch: 20 | Train Loss: 2.184 |  Val Loss: 798.218 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 30 | Train Loss: 2.151 |  Val Loss: 818.435 | Train acc: 0.0 | Val acc: 18.519\n",
      "Epoch: 40 | Train Loss: 2.087 |  Val Loss: 892.34 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 50 | Train Loss: 2.018 |  Val Loss: 828.222 | Train acc: 11.111 | Val acc: 22.222\n",
      "Epoch: 60 | Train Loss: 1.945 |  Val Loss: 958.254 | Train acc: 22.222 | Val acc: 29.63\n",
      "Epoch: 70 | Train Loss: 1.888 |  Val Loss: 1010.045 | Train acc: 33.333 | Val acc: 29.63\n",
      "Epoch: 80 | Train Loss: 1.831 |  Val Loss: 1099.346 | Train acc: 44.444 | Val acc: 29.63\n",
      "Epoch: 90 | Train Loss: 1.733 |  Val Loss: 921.445 | Train acc: 55.556 | Val acc: 33.333\n",
      "Epoch: 100 | Train Loss: 1.692 |  Val Loss: 1083.436 | Train acc: 77.778 | Val acc: 40.741\n",
      "Epoch: 110 | Train Loss: 1.621 |  Val Loss: 1661.985 | Train acc: 77.778 | Val acc: 33.333\n",
      "Epoch: 120 | Train Loss: 1.495 |  Val Loss: 1751.514 | Train acc: 88.889 | Val acc: 37.037\n",
      "Epoch: 130 | Train Loss: 1.404 |  Val Loss: 1784.015 | Train acc: 88.889 | Val acc: 33.333\n",
      "Epoch: 140 | Train Loss: 1.35 |  Val Loss: 1874.459 | Train acc: 88.889 | Val acc: 29.63\n",
      "Epoch: 150 | Train Loss: 1.285 |  Val Loss: 2227.616 | Train acc: 88.889 | Val acc: 44.444\n",
      "Epoch: 160 | Train Loss: 1.174 |  Val Loss: 2332.868 | Train acc: 88.889 | Val acc: 25.926\n",
      "Epoch: 170 | Train Loss: 1.095 |  Val Loss: 2171.07 | Train acc: 88.889 | Val acc: 29.63\n",
      "Epoch: 180 | Train Loss: 0.995 |  Val Loss: 2954.374 | Train acc: 100.0 | Val acc: 22.222\n",
      "Epoch: 190 | Train Loss: 0.954 |  Val Loss: 3650.563 | Train acc: 88.889 | Val acc: 22.222\n",
      "Epoch: 200 | Train Loss: 0.882 |  Val Loss: 3368.217 | Train acc: 100.0 | Val acc: 40.741\n",
      "--------k param: 0 k-fold num: 10 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.266 |  Val Loss: 233.66 | Train acc: 0.0 | Val acc: 11.111\n",
      "Epoch: 20 | Train Loss: 2.253 |  Val Loss: 79.267 | Train acc: 0.0 | Val acc: 22.222\n",
      "Epoch: 30 | Train Loss: 2.222 |  Val Loss: 121.092 | Train acc: 0.0 | Val acc: 18.519\n",
      "Epoch: 40 | Train Loss: 2.208 |  Val Loss: 228.425 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 50 | Train Loss: 2.202 |  Val Loss: 196.694 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 60 | Train Loss: 2.179 |  Val Loss: 168.695 | Train acc: 0.0 | Val acc: 22.222\n",
      "Epoch: 70 | Train Loss: 2.183 |  Val Loss: 236.383 | Train acc: 0.0 | Val acc: 11.111\n",
      "Epoch: 80 | Train Loss: 2.144 |  Val Loss: 273.399 | Train acc: 11.111 | Val acc: 22.222\n",
      "Epoch: 90 | Train Loss: 2.131 |  Val Loss: 238.361 | Train acc: 11.111 | Val acc: 14.815\n",
      "Epoch: 100 | Train Loss: 2.108 |  Val Loss: 326.232 | Train acc: 22.222 | Val acc: 18.519\n",
      "Epoch: 110 | Train Loss: 2.1 |  Val Loss: 329.949 | Train acc: 11.111 | Val acc: 11.111\n",
      "Epoch: 120 | Train Loss: 2.098 |  Val Loss: 411.686 | Train acc: 11.111 | Val acc: 11.111\n",
      "Epoch: 130 | Train Loss: 2.045 |  Val Loss: 524.808 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 140 | Train Loss: 2.036 |  Val Loss: 618.068 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 150 | Train Loss: 1.993 |  Val Loss: 694.646 | Train acc: 33.333 | Val acc: 14.815\n",
      "Epoch: 160 | Train Loss: 1.951 |  Val Loss: 646.692 | Train acc: 33.333 | Val acc: 14.815\n",
      "Epoch: 170 | Train Loss: 1.962 |  Val Loss: 912.74 | Train acc: 33.333 | Val acc: 18.519\n",
      "Epoch: 180 | Train Loss: 1.92 |  Val Loss: 1138.368 | Train acc: 33.333 | Val acc: 22.222\n",
      "Epoch: 190 | Train Loss: 1.896 |  Val Loss: 1438.066 | Train acc: 33.333 | Val acc: 18.519\n",
      "Epoch: 200 | Train Loss: 1.85 |  Val Loss: 1528.186 | Train acc: 44.444 | Val acc: 18.519\n",
      "--------k param: 0 k-fold num: 1 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.216 |  Val Loss: 54.21 | Train acc: 0.0 | Val acc: 7.407\n",
      "Epoch: 20 | Train Loss: 2.209 |  Val Loss: 68.604 | Train acc: 0.0 | Val acc: 7.407\n",
      "Epoch: 30 | Train Loss: 2.205 |  Val Loss: 61.749 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 40 | Train Loss: 2.137 |  Val Loss: 63.237 | Train acc: 0.0 | Val acc: 14.815\n",
      "Epoch: 50 | Train Loss: 2.154 |  Val Loss: 201.003 | Train acc: 0.0 | Val acc: 11.111\n",
      "Epoch: 60 | Train Loss: 2.109 |  Val Loss: 193.417 | Train acc: 0.0 | Val acc: 7.407\n",
      "Epoch: 70 | Train Loss: 2.055 |  Val Loss: 223.838 | Train acc: 11.111 | Val acc: 7.407\n",
      "Epoch: 80 | Train Loss: 2.05 |  Val Loss: 330.349 | Train acc: 22.222 | Val acc: 7.407\n",
      "Epoch: 90 | Train Loss: 2.001 |  Val Loss: 313.731 | Train acc: 11.111 | Val acc: 14.815\n",
      "Epoch: 100 | Train Loss: 1.945 |  Val Loss: 288.411 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 110 | Train Loss: 1.951 |  Val Loss: 515.682 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 120 | Train Loss: 1.895 |  Val Loss: 415.691 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 130 | Train Loss: 1.847 |  Val Loss: 482.978 | Train acc: 33.333 | Val acc: 25.926\n",
      "Epoch: 140 | Train Loss: 1.784 |  Val Loss: 547.608 | Train acc: 33.333 | Val acc: 22.222\n",
      "Epoch: 150 | Train Loss: 1.737 |  Val Loss: 569.649 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 160 | Train Loss: 1.71 |  Val Loss: 575.278 | Train acc: 44.444 | Val acc: 18.519\n",
      "Epoch: 170 | Train Loss: 1.691 |  Val Loss: 720.376 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 180 | Train Loss: 1.599 |  Val Loss: 805.098 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 190 | Train Loss: 1.544 |  Val Loss: 874.827 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 200 | Train Loss: 1.503 |  Val Loss: 994.395 | Train acc: 66.667 | Val acc: 22.222\n",
      "--------k param: 0 k-fold num: 2 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "---------------Initializing PCA-----------------\n",
      "---------------Transforming PTR features using PCA-----------------\n",
      "Epoch: 10 | Train Loss: 2.244 |  Val Loss: 323.88 | Train acc: 11.111 | Val acc: 14.815\n",
      "Epoch: 20 | Train Loss: 2.179 |  Val Loss: 575.954 | Train acc: 0.0 | Val acc: 11.111\n",
      "Epoch: 30 | Train Loss: 2.19 |  Val Loss: 516.161 | Train acc: 0.0 | Val acc: 18.519\n",
      "Epoch: 40 | Train Loss: 2.1 |  Val Loss: 373.037 | Train acc: 0.0 | Val acc: 22.222\n",
      "Epoch: 50 | Train Loss: 2.058 |  Val Loss: 690.074 | Train acc: 11.111 | Val acc: 14.815\n",
      "Epoch: 60 | Train Loss: 2.017 |  Val Loss: 679.435 | Train acc: 0.0 | Val acc: 22.222\n",
      "Epoch: 70 | Train Loss: 1.932 |  Val Loss: 1043.446 | Train acc: 0.0 | Val acc: 18.519\n",
      "Epoch: 80 | Train Loss: 1.96 |  Val Loss: 940.738 | Train acc: 11.111 | Val acc: 18.519\n",
      "Epoch: 90 | Train Loss: 1.867 |  Val Loss: 2147.821 | Train acc: 22.222 | Val acc: 14.815\n",
      "Epoch: 100 | Train Loss: 1.801 |  Val Loss: 2238.045 | Train acc: 22.222 | Val acc: 25.926\n",
      "Epoch: 110 | Train Loss: 1.768 |  Val Loss: 1712.605 | Train acc: 55.556 | Val acc: 22.222\n",
      "Epoch: 120 | Train Loss: 1.666 |  Val Loss: 2390.01 | Train acc: 66.667 | Val acc: 18.519\n",
      "Epoch: 130 | Train Loss: 1.633 |  Val Loss: 2265.021 | Train acc: 44.444 | Val acc: 22.222\n",
      "Epoch: 140 | Train Loss: 1.615 |  Val Loss: 3136.598 | Train acc: 44.444 | Val acc: 25.926\n",
      "Epoch: 150 | Train Loss: 1.514 |  Val Loss: 3157.578 | Train acc: 66.667 | Val acc: 18.519\n",
      "Epoch: 160 | Train Loss: 1.451 |  Val Loss: 3652.691 | Train acc: 66.667 | Val acc: 18.519\n",
      "Epoch: 170 | Train Loss: 1.379 |  Val Loss: 4522.167 | Train acc: 77.778 | Val acc: 29.63\n",
      "Epoch: 180 | Train Loss: 1.317 |  Val Loss: 4146.89 | Train acc: 77.778 | Val acc: 29.63\n",
      "Epoch: 190 | Train Loss: 1.194 |  Val Loss: 5004.226 | Train acc: 77.778 | Val acc: 22.222\n",
      "Epoch: 200 | Train Loss: 1.139 |  Val Loss: 5781.841 | Train acc: 77.778 | Val acc: 22.222\n",
      "--------k param: 0 k-fold num: 3 completed!-----------\n",
      "---------------Initializing bins-----------------\n",
      "---------------Determining PTR features-----------------\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-c72941ea7994>\", line 45, in <module>\n",
      "    prepare_pca_train_val_data(train_data_pca, val_data_pca, train_labels_pca, val_labels_pca, N_COMP)\n",
      "  File \"<ipython-input-8-8fbb044a93d5>\", line 23, in prepare_pca_train_val_data\n",
      "    features = FeatureSelection(train_data, n_pc=n_components)\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 25, in __init__\n",
      "    self.ptr_features = self.determine_ptr_features()\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 82, in determine_ptr_features\n",
      "    sample_features = self.determine_ptr_feature_vector(df[sample_idx])\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 99, in determine_ptr_feature_vector\n",
      "    passes = bin.count_passes_for_each_dimension(signal, self.n)\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 190, in count_passes_for_each_dimension\n",
      "    return self.count_passes_recursive(relevant_signal, n)\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 217, in count_passes_recursive\n",
      "    passes_total = np.add(passes, self.count_passes_recursive(remaining_signal[1:], n, next_iteration_inside))\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 217, in count_passes_recursive\n",
      "    passes_total = np.add(passes, self.count_passes_recursive(remaining_signal[1:], n, next_iteration_inside))\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 217, in count_passes_recursive\n",
      "    passes_total = np.add(passes, self.count_passes_recursive(remaining_signal[1:], n, next_iteration_inside))\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 211, in count_passes_recursive\n",
      "    if self.is_within_box(remaining_signal[0][dim]):\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\", line 221, in is_within_box\n",
      "    return self.y1 <= y <= self.y2\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"d:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\Program Files\\Python38\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\Program Files\\Python38\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c72941ea7994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mtransformed_train_data_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_val_data_pca\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     \u001b[0mprepare_pca_train_val_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_COMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                     \u001b[1;31m# Create data loaders for train-val for the current cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8fbb044a93d5>\u001b[0m in \u001b[0;36mprepare_pca_train_val_data\u001b[1;34m(train_data, val_data, train_labels_pca, val_labels_pca, n_components)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_pca_train_val_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatureSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mtransformed_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_training_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, n_pc, U, V, K)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------Determining PTR features-----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptr_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetermine_ptr_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------Initializing PCA-----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mdetermine_ptr_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0msample_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetermine_ptr_feature_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mdetermine_ptr_feature_vector\u001b[1;34m(self, signal)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mpasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_for_each_dimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_for_each_dimension\u001b[1;34m(self, signal, n)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mrelevant_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelevant_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mpasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mpasses_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpasses_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mpasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mpasses_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpasses_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mpasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mpasses_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpasses_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mpasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mpasses_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpasses_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mpasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mpasses_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_passes_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpasses_total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mcount_passes_recursive\u001b[1;34m(self, remaining_signal, n, inside)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minside\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_within_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m                     \u001b[0mnext_iteration_inside\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\passing_through_regions.py\u001b[0m in \u001b[0;36mis_within_box\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_within_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2047\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             )\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PythonProjects\\JapaneseSpeechRecognition\\.venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import os\n",
    "from operator import itemgetter \n",
    "\n",
    "## Move model to cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dict_of_k_results = dict()\n",
    "\n",
    "# Initialize cross valudator\n",
    "cross_validator = create_cross_validator(n_splits=K_FOLD_SPLITS)\n",
    "for curr_dropout in range_of_dropout:\n",
    "    dropout_rate = curr_dropout\n",
    "    for k in range(LOOP_START_AT,K+1):\n",
    "\n",
    "            # If we can the process the data at once.\n",
    "            # Valid for all methods except PCA\n",
    "            if TYPE_OF_FEATURES != 'passing_regions_PCA':\n",
    "                # Prepare data\n",
    "                prepared_data = prepare_dataset(type=TYPE_OF_FEATURES, k=k)\n",
    "            else:\n",
    "                prepared_data = list_of_trains\n",
    "\n",
    "            k_fold_num = 0\n",
    "            for train_idx, val_idx in cross_validator.split(prepared_data):\n",
    "                start_time_current_k_fold = datetime.now()\n",
    "                k_fold_num += 1\n",
    "\n",
    "                if TYPE_OF_FEATURES != 'passing_regions_PCA':\n",
    "                    # Create data loaders for train/val for the current cross validation\n",
    "                    train_loader, val_loader = create_data_loaders(\n",
    "                        train_data=itemgetter(*train_idx)(prepared_data),\n",
    "                        val_data=itemgetter(*val_idx)(prepared_data))\n",
    "                else:\n",
    "                    # 'list_of_trains' is the original training data without anything made to it\n",
    "                    # Separate data depending on the indexes from the current cross validation\n",
    "                    train_data_pca = itemgetter(*train_idx)(list_of_trains)\n",
    "                    val_data_pca = itemgetter(*val_idx)(list_of_trains)\n",
    "                    train_labels_pca = itemgetter(*train_idx)(list_of_train_labels)\n",
    "                    val_labels_pca = itemgetter(*val_idx)(list_of_train_labels)\n",
    "                    # Fit transform the training and just transform the validation\n",
    "                    transformed_train_data_pca, transformed_val_data_pca = \\\n",
    "                    prepare_pca_train_val_data(train_data_pca, val_data_pca, train_labels_pca, val_labels_pca, N_COMP)\n",
    "                    # Create data loaders for train-val for the current cross validation\n",
    "                    train_loader, val_loader = \\\n",
    "                    create_data_loaders(train_data=transformed_train_data_pca, val_data=transformed_val_data_pca)\n",
    "\n",
    "                    \n",
    "                # get feature dimensionality to set in the network\n",
    "                feature_dim = next(iter(train_loader))[0].shape[1]\n",
    "\n",
    "                ## Initialize model\n",
    "                model = JapaneseVowelsNN(feature_dim=feature_dim, num_classes=NUM_CLASSES,dropout_rate=dropout_rate)\n",
    "                model = model.double()\n",
    "                model.to(device)\n",
    "\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                if optimizer_name == 'Adam':\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "                elif optimizer_name == 'RMSProp':\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "                elif optimizer_name == 'Adagrad':\n",
    "                    optimizer = optim.Adagrad(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "                with torch.cuda.device(0):\n",
    "                    for epoch in range(1, EPOCHS+1):\n",
    "                        # TRAINING\n",
    "                        train_epoch_loss = 0\n",
    "                        train_epoch_acc = 0\n",
    "                        model.train()\n",
    "                        for X_train_batch, y_train_batch in train_loader:\n",
    "                            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "                            \n",
    "                            y_train_pred = model(X_train_batch)\n",
    "                            \n",
    "                            train_loss = criterion(y_train_pred, y_train_batch)\n",
    "                            train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "                            \n",
    "                            train_loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                            train_epoch_loss += train_loss.item()\n",
    "                            train_epoch_acc += train_acc.item()\n",
    "                            \n",
    "                            \n",
    "                        # VALIDATION    \n",
    "                        with torch.no_grad():\n",
    "                            \n",
    "                            val_epoch_loss = 0\n",
    "                            val_epoch_acc = 0\n",
    "                            \n",
    "                            model.eval()\n",
    "                            for X_val_batch, y_val_batch in val_loader:\n",
    "                                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                                \n",
    "                                y_val_pred = model(X_val_batch)\n",
    "                                            \n",
    "                                val_loss = criterion(y_val_pred, y_val_batch)\n",
    "                                val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "                                \n",
    "                                val_epoch_loss += val_loss.item()\n",
    "                                val_epoch_acc += val_acc.item()\n",
    "                        \n",
    "                        if epoch % 10 == 0:\n",
    "                            print(\"Epoch: {} | Train Loss: {} |  Val Loss: {} | Train acc: {} | Val acc: {}\".format(epoch,                                                  round(train_epoch_loss/len(train_loader),3), round(val_epoch_loss/len(val_loader),3), round                                                     (train_epoch_acc/len(train_loader),3), round(val_epoch_acc/len(val_loader),3)))\n",
    "                            #print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "                            #print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "                        if epoch == EPOCHS:\n",
    "                            print('--------k param: {} k-fold num: {} completed!-----------'.format(k, k_fold_num))\n",
    "                \n",
    "                ## Check if key exists and create it if it doesnt and saves the results for the current k-fold\n",
    "                if k not in dict_of_k_results:\n",
    "                    dict_of_k_results[k] = {'train_acc':[], 'train_loss':[], 'val_acc':[],'val_loss':[],                                                                'type':TYPE_OF_FEATURES, 'convergence_time':[]}\n",
    "\n",
    "                end_time_current_k_fold = datetime.now()\n",
    "                dict_of_k_results[k]['train_acc'].append(train_epoch_acc/len(train_loader))\n",
    "                dict_of_k_results[k]['train_loss'].append(train_epoch_loss/len(train_loader))\n",
    "                dict_of_k_results[k]['val_acc'].append(val_epoch_acc/len(val_loader))\n",
    "                dict_of_k_results[k]['val_loss'].append(val_epoch_loss/len(val_loader))\n",
    "                dict_of_k_results[k]['convergence_time'].append(end_time_current_k_fold-start_time_current_k_fold)\n",
    "            \n",
    "            # Check if folder structure is created, if not - create it\n",
    "            if not os.path.isdir('{}\\\\Results\\\\{}\\\\{}\\\\'.format(os.getcwd(),TYPE_OF_FEATURES, sub_folder)):\n",
    "                os.makedirs('{}\\\\Results\\\\{}\\\\{}\\\\'.format(os.getcwd(),TYPE_OF_FEATURES, sub_folder))\n",
    "            # Save results as pickles\n",
    "            with open('{}\\\\Results\\\\{}\\\\{}\\\\dict_of_k_results_cv{}_dropout-{}_3-layered_{}_epochs_{}_lr_{}.pkl'.\n",
    "                format(os.getcwd(),TYPE_OF_FEATURES,sub_folder,K_FOLD_SPLITS,dropout_rate,optimizer_name,EPOCHS,LEARNING_RATE), 'wb')                   as handle:\n",
    "                    pickle.dump(dict_of_k_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "### Just trying some stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}